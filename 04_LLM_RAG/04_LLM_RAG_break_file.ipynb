{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e84ada01",
   "metadata": {},
   "source": [
    "# From LLMs to RAG (Student Exercise - Colab Version)\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/suthekshan/Agentic-Ai-Foundations/blob/main/04_LLM_RAG/04_LLM_RAG_colab_student_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "This notebook is a 'tunable' version of the RAG implementation designed for Google Colab.\n",
    "**Your Task:** The logic is implemented for you, but the **parameters** are missing or need tuning. \n",
    "Fill in the variables marked with `___` to get the code running, then experiment with different values to optimize the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc7aa5c",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "Since we are in Colab, we need to install the necessary libraries first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d2ab61",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "Since we are in Colab, we need to install the necessary libraries first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6d426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-community langchain-chroma langchain-text-splitters langchain-groq langchain-huggingface sentence-transformers pypdf python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80d903d",
   "metadata": {},
   "source": [
    "## 2. API Key Setup\n",
    "Enter your Groq API key below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb985f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "# Best practice in Colab: Use the \"Secrets\" feature (key icon on the left).\n",
    "# Name your secret 'GROQ_API_KEY'.\n",
    "try:\n",
    "    os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')\n",
    "except:\n",
    "    # Fallback if secrets are not used\n",
    "    import getpass\n",
    "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your GROQ_API_KEY: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071daa80",
   "metadata": {},
   "source": [
    "## 3. Download Data\n",
    "We will download the sample PDF directly from the repository so you don't have to upload it manually.\n",
    "try downloading anyother pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97435cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/suthekshan/Agentic-Ai-Foundations/main/04_LLM_RAG/pdf1.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6664a9",
   "metadata": {},
   "source": [
    "## 4. Document Loading\n",
    "We use `PyPDFLoader` to load the PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61e82cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_path = \"pdf1.pdf\"\n",
    "\n",
    "# Logic is provided, just run it\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "# Check how many pages we have\n",
    "if documents:\n",
    "    print(f\"Loaded {len(documents)} pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cabcff3",
   "metadata": {},
   "source": [
    "## 5. Text Chunking (Tunable)\n",
    "\n",
    "This is a critical step. You need to define how large the chunks are and how much they overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7572698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# TODO: Tuning Step 1\n",
    "# Experiment with different chunk sizes (e.g., 500, 1000, 2000)\n",
    "chunk_size_val = ___ \n",
    "\n",
    "# TODO: Tuning Step 2\n",
    "# Experiment with overlap (e.g., 0, 100, 200). meaningful overlap helps preserve context.\n",
    "chunk_overlap_val = ___\n",
    "\n",
    "# The logic uses your parameters:\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size_val,\n",
    "    chunk_overlap=chunk_overlap_val\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "if texts:\n",
    "    print(f\"Created {len(texts)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34875e84",
   "metadata": {},
   "source": [
    "## 6. Embeddings\n",
    "Select the embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b60ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# TODO: Specify the model name\n",
    "# Common option: \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "# Explore anyother model from https://huggingface.co/models?pipeline_tag=sentence-transformers&sort=downloads\n",
    "model_name_val = \"___\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60bd4cc",
   "metadata": {},
   "source": [
    "## 7. Vector Store\n",
    "Initialize ChromaDB with your parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787a1617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# TODO: Name your collection\n",
    "collection_name_val = \"___\"\n",
    "\n",
    "# Logic to create/load the vector store\n",
    "vector_store = Chroma(\n",
    "    collection_name=collection_name_val,\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_db_colab\" \n",
    ")\n",
    "\n",
    "if vector_store._collection.count() == 0:\n",
    "    vector_store.add_documents(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c96b57",
   "metadata": {},
   "source": [
    "## 8. Retriever (Tunable)\n",
    "The retrieval step is highly sensitive to `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fac75e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Tuning Step 3\n",
    "# Set 'k' - the number of documents to retrieve.\n",
    "# Try small values (1) and larger values (5).\n",
    "k_val = ___ \n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": k_val})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd5b6dd",
   "metadata": {},
   "source": [
    "## 9. LLM Setup (Tunable)\n",
    "Configure the LLM generation parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102a48eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# TODO: Tuning Step 4\n",
    "# Experiment with temperature (0.0 = deterministic, 1.0 = creative)\n",
    "temperature_val = ___ \n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=temperature_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780ef357",
   "metadata": {},
   "source": [
    "## 10. Prompt Template (Tunable)\n",
    "The prompt instructions (system prompt) can changed to improve results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d500552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# TODO: Tuning Step 5\n",
    "# Define the prompt template. It MUST include {context} and {query}.\n",
    "prompt_template_str = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eeb425",
   "metadata": {},
   "source": [
    "## 11. RAG Chain Construction\n",
    "The pipeline logic is pre-built for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c47e898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# The Chain Logic\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"query\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a078dc77",
   "metadata": {},
   "source": [
    "## 12. Testing\n",
    "Run the chain with your parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0610d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the main topic of the document?\"\n",
    "\n",
    "# Invoke the chain\n",
    "response = rag_chain.invoke(question)\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
